{
  "articles": [
    {
      "path": "correlated_genetic_data.html",
      "title": "Characteristics of Genetic Data",
      "description": "In this section, we'll touch on the problems associated with genetic data being correlated and sparse, and then get to know some methods to resolve them. \n",
      "author": [],
      "contents": "\n1. Genetic data are correlated\nThe first question we need to ask ourselves is: What does it mean to say that genetic data are correlated? Genetic data can be correlated in two ways:\na. Genetic data are correlated among Single nucleotide polymorphisms (SNPs), aka correlated columns in the dataset\nFirst, a recap: SNP is a genetic variation in the DNA that occurs at a single base location. The influence of SNPs on attributes including health conditions, diseases, and treatment responses is a topic of research for scientists. In genetic data, a SNP variable has 3 values: 0 = homozygous dominant alleles, 1 = heterozygous alleles (1 major and 1 minor), 2 = homozygous minor alleles\n\n\n\nThe closer SNPs are in terms of distance, the more correlated they are with one another. This concept is called Linkage Disequilibrium (LD). LD is represented in the heatmap below, which shows the squared correlation between SNP pairs in European Americans from the HapMap dataset. Since the orange shades show the highest correlation, we see that these shades lie up along the diagonal line, representing the location of pairs of SNPs that neighbor to one another.\n\n\n\nWhere does LD come from?\nLD is the result of recombination, which is an exchange in genetic material to form a new pair of chromosomes for the offspring. Specifically, the offspring inherits the genetic materials from both parents, but not in the exact order as the parents’ chromosomes. Either or both of the chromosomes from each parent’s chromosome pair will “recombine” through cross-over, as observed in this diagram.\n\n\n\nSince linkage is the probability that two segments of DNA are inherited together, SNPs that are closer in terms of distance on the chromosome are more likely to be inherited together. As the SNPs are not independently distributed and uniformly distanced on the chromosome, there’s a disequilibrium.\n\n\n\nThe merit of LD\nOne advantage is that if we have limited genetic data which do not contain the causal SNPs for the disease trait of interest, we can obtain significant results for SNPs neighboring those causal SNPs and narrow down the “SNP causal zone”. This allows subsequent research to focus more on collecting data in this area to determine the causal SNP.\n\n\n\n…But the problems are…\nProblem 1: Difficult to figure out the causal SNPs\nIf a lot of the SNPs are significant, it will be hard to determine the exact SNP(s) that cause the disease to zoom in on them.\n\n\n\n(Cano-Gamez and Trynka 2020)\nProblem 2: Hard to determine the p-value threshold in Multiple Testing\n\nBut first, a review:\n\nMultiple Testing is the process of carrying out more than one hypothesis test simultaneously. The problem associated with Multiple Testing is the change in the p-value threshold and hence an increase in the number of Type 1 errors (T1E) made. Specifically, if we conduct a single hypothesis test, the probability of making a T1E is equal to our significance level \\(\\alpha\\), which is typically set at 0.05. However, when we do multiple tests, we have more chances to make T1E, and the probability of making at least a T1E increases. For example, if we conduct 20 tests, the probability that we make at least one T1E is\n\\[1 - (1 - 0.05)^{20}  \\approx  0.6415\\]\nwhere \\(\\alpha = 0.05\\), the number of tests \\(= 20\\), \\(1 - 0.05\\) = the probably of making no T1E in a test. The result \\(0.6415\\) is much greater than what we want \\(0.05\\).\nMethods to address the problems\nThere are two methods used to correct the p-value threshold for Multiple Testing situations: Bonferroni Correction and the Simulation-based Approach. Bonferroni Correction is a very popular approach in which we obtain our new p-value threshold by dividing our desired alpha, or the desired probability of making a T1E, typically 0.05 by the number of tests we’re conducting. For the Simulation-based Approach, we simulate a null trait, which is a trait that’s not associated with any of the SNPs, using GWAS and record the smallest p- values. Repeat this around 500-1000 times, and our new p-value threshold is the value at the lowest 5th percentile.\nHowever, since Bonferroni Correction operates under the assumption that all of the SNPs are independent, the p-value threshold determined using this method tends to be very low. Therefore, the Simulation-based Approach is a more reliable method to determine the p-value threshold in the case of LD.\nb. Genetic data are correlated among individuals, aka correlated columns in the dataset\nRelatedness Concepts\nThere are two different types of relatedness among the people in the dataset. They are:\nFamily relatedness: known relationships that are established based on a (usually recent) common ancestor (e.g. siblings, parents, children, cousins)\nCryptic relatedness: unknown family relationships, often between more distant relatives who have (a) common ancestor(s)\nThe problem\nWhen we use standard techniques, e.g. linear regression, these two types of relatedness confound the analysis, which leads to the underestimation of standard errors. This makes the test statistic bigger (inflated) and, as a result, makes the p-value smaller than it actually is (inflated). When the p-value is inflated, the chance of making T1E increases.\n\\[\\frac{\\text{Estimate}}{\\text{Correct SE}} < \\frac{\\text{Estimate}}{\\text{Too small/Underestimated SE}}\\]\nOr better yet, with a visualization:\nSmall test statistic → large p-value\n\n\n\nLarge test statistic → small p-value\n\n\n\nMethods to address the problem\nIn order to address this problem, we have to consider methods that can infer genetic ancestry in order to stratify the relatedness in the population.\n\nPCA has been used for a long time to infer population structure in genetic data for a long time.\n\nPros:\nPCA will correct markers with large differences in allele frequency across ancestral populations\nUsing ancestry-informative markers (AIMs), PCA may predict genetic ancestry and correct for stratification in the absence of genome-wide data. This works because large differences in allele frequency between subpopulations that are genotyped to infer genetic ancestry in new samples have been linked to AIMs.\nCons:\nPCA does not explicitly model family structure or cryptic relatedness, which could inflate test statistics.\nThe population structure is not always reflected by the top primary components. Instead, they may reflect the presence of assay artifacts, long-range linkage disequilibrium, or familial resemblance. These effects can be eliminated by removing related samples, areas of long-range linkage disequilibrium, and low-quality data.\n\nAnother alternative is to use family-based association test.\n\nPros:\nSince transmitted and untransmitted alleles share the same genetic ancestry, family-based association tests concentrating on within-family information are immune to stratification.\nCons:\nHowever, fully powered statistics for family-based studies must take into account between-family information. This can be addressed by converting between-family information into a rank statistic (rank of association) prior to combining within and between family information, which ensures that both sources of information are resistant to stratification.\nLinear Mixed Model\nOne of the methods that incorporate family-based association tests is Mixed Models, which can model population structure, family structure, and cryptic relatedness. A mixed model is a model that combines both fixed effects and random effects. While fixed effects are variables that are constant across individuals, random effects are variables that have different levels across the population.\nLet’s take a look at an example between GPA and absences. If we just look at the general trend between absence and GPA, we can see that there’s a linear downward trend. However, when we look further into the characteristics of the students, we can see that they are either from high or low-income backgrounds, which confounds the association between GPA and absence. Therefore, in this case, absence is the fixed effect, and income background is the random effect.\n\n\n\n\n\n\nSimilarly, in genetic data, family structure and cryptic relatedness are random effects. Population structure is arguably the fixed effect, specifically in the paper New approaches to population stratification in genome-wide association studies by Price et al (Price et al. 2010), since modeling it as a random effect can result in spurious associations.\n\n\n\n(Mlblevins 2015)\nExample of Linear Mixed Model\nIn order to demonstrate the Linear Mixed Model, let’s explore a real example: Data on Dragons. Our objective in this analysis is to model testScore based on other variables like bodyLength and mountainRange. This example is available at https://ourcodingclub.github.io/tutorials/mixed-models/.\nLet’s take a look at the data\n\n  testScore bodyLength mountainRange  X site\n1 16.147309   165.5485      Bavarian NA    a\n2 33.886183   167.5593      Bavarian NA    a\n3  6.038333   165.8830      Bavarian NA    a\n4 18.838821   167.6855      Bavarian NA    a\n5 33.862328   169.9597      Bavarian NA    a\n6 47.043246   168.6887      Bavarian NA    a\n\nFirst, we fit a basic linear model using the scaled bodyLength variable, denoted by bodyLength2, to model testScore. Let’s go!\n\n\n# Scale the bodyLength variable\ndragons$bodyLength2 <- scale(dragons$bodyLength, center = TRUE, scale = TRUE)\n\n# Fit a linear model between bodyLength and testScore\nbasic.lm <- lm(testScore ~ bodyLength2, data = dragons)\nsummary(basic.lm)\n\n\nCall:\nlm(formula = testScore ~ bodyLength2, data = dragons)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-56.962 -16.411  -0.783  15.193  55.200 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  50.3860     0.9676  52.072   <2e-16 ***\nbodyLength2   8.9956     0.9686   9.287   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.2 on 478 degrees of freedom\nMultiple R-squared:  0.1529,    Adjusted R-squared:  0.1511 \nF-statistic: 86.25 on 1 and 478 DF,  p-value: < 2.2e-16\n\nUsing ggplot, we can obtain a sneak peek of what the linear line looks like. How exciting!\n\n\n\nFrom this plot, we may conclude that dragons with longer body are more intelligent.\nBut if we take a minute to think about it, that’s a bit off intuitively: how long the dragons are should not effect their intelligence, just as how a person’s height shouldn’t have anything to do with their intellegence. Then, what’s happening here?\nIn order to investigate further, let’s color the above graph with the mountainRange variable.\n\n\n\nOh wow, can you see that? If you look closely at different mountain ranges, the trend between dragons’ body length and intellgence, measured by the testScore variable, seems very random. This shows that the observations from different mountain ranges are not independent. In other words, we cannot analyze the observations in different mountain ranges together since data in the same mountain ranges are likely to be correlated with one another.\nWe can investigate that by looking at the trend in the data by mountain range, as shown in the following graph\n\n\n\nThis confirms our hypothesis that there are no clear trend between dragon’s body length and test score.\nLet’s look further into the modelling process, specifically comparing the coefficients between the normal linear regression vs. the Linear Mixed Model.\nLinear Regression between Dragon’s Body Length and Test Score\n\n\nCall:\nlm(formula = testScore ~ bodyLength2, data = dragons)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-56.962 -16.411  -0.783  15.193  55.200 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  50.3860     0.9676  52.072   <2e-16 ***\nbodyLength2   8.9956     0.9686   9.287   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.2 on 478 degrees of freedom\nMultiple R-squared:  0.1529,    Adjusted R-squared:  0.1511 \nF-statistic: 86.25 on 1 and 478 DF,  p-value: < 2.2e-16\n\nSince the bodyLength variable has a p-value < 0.05, there seems to be an association between body length and test score. However, if we add the mountainRange variable, we’ll see a change in the significance of the bodyLength variable.\n\n\nCall:\nlm(formula = testScore ~ bodyLength2 + mountainRange, data = dragons)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-52.263  -9.926   0.361   9.994  44.488 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)            23.3818     2.5792   9.065  < 2e-16 ***\nbodyLength2             0.2055     1.2927   0.159  0.87379    \nmountainRangeCentral   36.5828     3.5993  10.164  < 2e-16 ***\nmountainRangeEmmental  16.2092     3.6966   4.385 1.43e-05 ***\nmountainRangeJulian    45.1147     4.1901  10.767  < 2e-16 ***\nmountainRangeLigurian  17.7478     3.6736   4.831 1.84e-06 ***\nmountainRangeMaritime  49.8813     3.1392  15.890  < 2e-16 ***\nmountainRangeSarntal   41.9784     3.1972  13.130  < 2e-16 ***\nmountainRangeSouthern   8.5196     2.7313   3.119  0.00192 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.96 on 471 degrees of freedom\nMultiple R-squared:  0.5843,    Adjusted R-squared:  0.5773 \nF-statistic: 82.76 on 8 and 471 DF,  p-value: < 2.2e-16\n\nNow, when we look at the coefficient for the bodyLength variable, bodyLength is not significant. However, the coefficients for the mountain ranges are significant. This means that mountainRange is a good predictor of test scores, meaning that test scores vary across the different mountain ranges. Therefore, we can see that being on different mountain ranges is a random factor and hence it has a random effect. As a result, we must control it in order to come to an accurate conclusion for the association between the dragon’s body length and test score.\nThis is where Linear Mixed Model comes into play!\nIn order to implement this method, we have to install the lme4 library.\n\n\n\nIn the following model, our question is What is the effect of the Dragon’s body length on test score after we control for mountain range? We use the syntax (1|mountainRange) to signal that we want to control for the random effect mountainRange\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: testScore ~ bodyLength2 + (1 | mountainRange)\n   Data: dragons\n\nREML criterion at convergence: 3985.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.4815 -0.6513  0.0066  0.6685  2.9583 \n\nRandom effects:\n Groups        Name        Variance Std.Dev.\n mountainRange (Intercept) 339.7    18.43   \n Residual                  223.8    14.96   \nNumber of obs: 480, groups:  mountainRange, 8\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  50.3860     6.5517   7.690\nbodyLength2   0.5377     1.2750   0.422\n\nCorrelation of Fixed Effects:\n            (Intr)\nbodyLength2 0.000 \n\nFor the Random effects section, it shows the amount of variance that’s captured by the mountainRange variable and the residual variance that’s not explained by mountainRange and bodyLength. In order to find out how much left-over variance in the Dragon’s test scores after accounting for bodyLength is explained by the mountainRange variable, we can divide the variance for mountainRange by total variance:\n\n[1] 0.6028394\n\nIt turns out that mountainRange explains around 60% of the left-over variance in the Dragon’s test scores, which is the variance remained after being explained by our fixed effect bodyLength. That’s a lot!\nNow, we can look at the Fixed effects section. Since the p-value for the bodyLength coefficient is 0.422 > 0.05, we can conclude that there is no association between bodyLength and testScore.\nWe can look at the residual plot for the Linear Mixed Model in order to check our assumption.\n\n\n\nSince the residuals contain no clear patterns, we can safely conclude that the Linear Mixed Model that we fitted is sufficient to investigate this dataset.\nc. Conclusion\nTo generalize it back to the GWAS context, we can account for family and cryptic relatedness as random effects and population structure as a fixed effect in the genetic data using Linear Mixed Model.\n\n\n\nCano-Gamez, Eddie, and Gosia Trynka. 2020. “From GWAS to Function: Using Functional Genomics to Identify the Mechanisms Underlying Complex Diseases.” Frontiers in Genetics 11. https://doi.org/10.3389/fgene.2020.00424.\n\n\nMlblevins. 2015. “Spurious Correlation Explained with Examples.” Psychologenie. https://psychologenie.com/spurious-correlation-explained-with-examples.\n\n\nPrice, Alkes L, Noah A Zaitlen, David Reich, and Nick Patterson. 2010. “New Approaches to Population Stratification in Genome-Wide Association Studies.” Nature Reviews Genetics 11 (7): 459–63.\n\n\n\n\n",
      "last_modified": "2022-12-09T11:54:21-05:00"
    },
    {
      "path": "ethics.html",
      "title": "Ethics",
      "description": "In this section, we'll explore ethics issues with Genome-Wide Association Studies (GWAS) and the guidelines on addressing them. \n",
      "author": [],
      "contents": "\nThe problem\nIn GWAS, race, ethnicity, and ancestry terminologies are used interchangeably to refer to biological genetic ancestry and social structures that are not the same, which may create stigma towards certain racial groups. Therefore, it is crucial to establish guidelines on the use of race, ethnicity, and ancestry terminology as well as analysis techniques in order to ensure fairness in all of the steps of a GWAS study, including concept definition, data sampling, data analysis, and reporting.\nThe guidelines\nThe researchers at NHLBI TOPMed establish guidelines that are broken down into 4 categories:\nTerminology, related to communicating manners using racial terminologies.\nHarmonization of race and ethnicity across studies, related to data collecting, sampling, and combining/harmonizing\nAnalysis, related to usage of analysis methods that avoid creating biases\nReporting, related to reporting manners that indicates a larger social context to avoid stigmatizing racial groups)\n\n\n\n(Khan et al. 2022)\nReflection\nData analysis are carried out by humans, who harbor various biases. Since it’s an evolutionary trait, it’s not to be blamed for. However, it’s something that we have to recognize in order to minimize. I’ve watched some documentaries, including Coded Bias, on how biased data can perpetuate biases associated with marginalized groups of people and potentially marginalize them even further.\nIt’s very enlightening to read these guidelines as they have broken down biases in GWAS into four clear buckets: terminology, data sampling, data analysis, and data reporting. I find terminology and data reporting the most fascinating. As a data scientist, I pay closer attention to the methods I employ in data sampling and analysis. However, I find myself being less critical when defining the variables and reporting the results. Also, a potential danger is, in order to make the story compelling, I tend to relate the insights to real-life observations, which may harbor my own biases. Therefore, these guidelines encourage me to reflect on different stages of working with data, enabling me to recognize my biases and paint as accurate a picture as possible to the subject at hand.\n\n\n\nKhan, Alyna T., Stephanie M. Gogarten, Caitlin P. McHugh, Adrienne M. Stilp, Tamar Sofer, Michael L. Bowers, Quenna Wong, et al. 2022. “Recommendations on the Use and Reporting of Race, Ethnicity, and Ancestry in Genetic Research: Experiences from the NHLBI TOPMed Program.” Cell Genomics 2 (8): 100155. https://doi.org/https://doi.org/10.1016/j.xgen.2022.100155.\n\n\n\n\n",
      "last_modified": "2022-12-09T11:54:22-05:00"
    },
    {
      "path": "index.html",
      "title": "Content Summary 3: Correlation and Sparsity in Genetic Data, as well as Ethical Issues in GWAS",
      "description": "By Thu Dang\n\nTo Kelsey: I try to make this as aesthetic as possible, and I hope you like it!\n",
      "author": [],
      "contents": "\nThroughout our journey together, you’ve probably realized that genetics data are enormous and complicated. Today, we’re going to explore two other characteristics that researchers usually encounter in Genome-wide Association Studies (GWAS):\nGenetic data are correlated\nGenetic data are sparse\nWe will also touch on some ethic issues that arise while carrying out GWAS research. This lesson will help you explore each of these two topics one by one. Click on the section of interest on the menu bar to get started!\n\n\n\n",
      "last_modified": "2022-12-09T11:54:23-05:00"
    },
    {
      "path": "sparse_genetic_data.html",
      "title": "Characteristics of Genetic Data",
      "description": "In this section, we'll touch on the problems associated with genetic data being correlated and sparse, and then get to know some methods to resolve them. \n",
      "author": [],
      "contents": "\n2. Genetic data are sparse\nThe problem\nGenetic data contain a lot of zeroes! This is due to the fact that there are many rare genetic variants.\n\n\n\nIn this graph (Casper-Emil Tingskov Pedersen 2016), we can see that the density of alleles differs across different populations. Specifically, we have to sample data from a lot of populations in order to increase the chance of obtaining the genetic variants of interest. This process can be time-consuming and expensive, and the analysis can be computationally-extensive with a huge amount of data.\nSince a lot of the currently available methods do not perform well on rare variants, this poses challenges to potential analysis, resulting in lower power or more T1Es in certain settings.\nMethods to address the problems\nOne of the proposed solutions is to combine information across genes and analyze that combined information together with the trait of interest.\n\n\n\n(Ma 2015)\n\n\n\nCasper-Emil Tingskov Pedersen, Niels Grarup, Kirk E Lohmueller. 2016. “The Effect of an Extreme and Prolonged Population Bottleneck on Patterns of Deleterious Variation: Insights from the Greenlandic Inuit.” https://www.researchgate.net/publication/311348232_The_Effect_of_an_Extreme_and_Prolonged_Population_Bottleneck_on_Patterns_of_Deleterious_Variation_Insights_from_the_Greenlandic_Inuit.\n\n\nMa, Clement. 2015. “Genetic Association Analysis.” https://slideplayer.com/slide/13370408/.\n\n\n\n\n",
      "last_modified": "2022-12-09T11:54:24-05:00"
    }
  ],
  "collections": []
}
